{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This Jupyter notebook compares the accuracies of the various machine learning models used. The model that gives the \n",
    "#highest accuracy and precison is selected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "#from sklearn.datasets import load_files\n",
    "#nltk.download('stopwords')\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import sklearn.discriminant_analysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "import sklearn.discriminant_analysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.svm import SVC\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"data.csv\")\n",
    "df['label'] = df['Text Label'].map({'Non-Bullying': 0, 'Bullying': 1})\n",
    "df['message']=df['Tweet']\n",
    "df.drop(['Text Label','Tweet'],axis=1,inplace=True)\n",
    "X = df['message']\n",
    "y = df['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    yeah I got 2 backups for all that. I just hate...\n",
      "1    I hate using my BB  but love my iPhone. Haven'...\n",
      "2                               Get fucking real dude.\n",
      "3     She is as dirty as they come  and that crook ...\n",
      "4     why did you fuck it up. I could do it all day...\n",
      "Name: message, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X.head())\n",
    "# Extract Feature With CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(X) # Fit the Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rashi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1942  340]\n",
      " [ 668  471]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.85      0.79      2282\n",
      "           1       0.58      0.41      0.48      1139\n",
      "\n",
      "    accuracy                           0.71      3421\n",
      "   macro avg       0.66      0.63      0.64      3421\n",
      "weighted avg       0.69      0.71      0.69      3421\n",
      "\n",
      "0.7053493130663548\n"
     ]
    }
   ],
   "source": [
    "LogisticR = LogisticRegression()\n",
    "LogisticR.fit(X_train, y_train) \n",
    "y_pred = LogisticR.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "LR = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1942  340]\n",
      " [ 668  471]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.85      0.79      2282\n",
      "           1       0.58      0.41      0.48      1139\n",
      "\n",
      "    accuracy                           0.71      3421\n",
      "   macro avg       0.66      0.63      0.64      3421\n",
      "weighted avg       0.69      0.71      0.69      3421\n",
      "\n",
      "0.7053493130663548\n"
     ]
    }
   ],
   "source": [
    "RandomForest = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "RandomForest.fit(X_train, y_train) \n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "RF = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1977  305]\n",
      " [ 713  426]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.87      0.80      2282\n",
      "           1       0.58      0.37      0.46      1139\n",
      "\n",
      "    accuracy                           0.70      3421\n",
      "   macro avg       0.66      0.62      0.63      3421\n",
      "weighted avg       0.68      0.70      0.68      3421\n",
      "\n",
      "0.7024261911721719\n"
     ]
    }
   ],
   "source": [
    "AdaBoost = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "AdaBoost.fit(X_train, y_train)\n",
    "AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "y_pred = AdaBoost.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "AB= accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1791  491]\n",
      " [ 637  502]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76      2282\n",
      "           1       0.51      0.44      0.47      1139\n",
      "\n",
      "    accuracy                           0.67      3421\n",
      "   macro avg       0.62      0.61      0.62      3421\n",
      "weighted avg       0.66      0.67      0.66      3421\n",
      "\n",
      "0.670271850336159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rashi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "SGD = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5)\n",
    "SGD.fit(X_train, y_train)\n",
    "SGDClassifier(max_iter=5)\n",
    "y_pred = SGD.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "SGDA = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1154 1128]\n",
      " [ 396  743]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.51      0.60      2282\n",
      "           1       0.40      0.65      0.49      1139\n",
      "\n",
      "    accuracy                           0.55      3421\n",
      "   macro avg       0.57      0.58      0.55      3421\n",
      "weighted avg       0.63      0.55      0.57      3421\n",
      "\n",
      "0.5545162233265127\n"
     ]
    }
   ],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "KNN.fit(X_train, y_train)\n",
    "y_pred = KNN.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "KNNA = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1710  572]\n",
      " [ 611  528]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.74      2282\n",
      "           1       0.48      0.46      0.47      1139\n",
      "\n",
      "    accuracy                           0.65      3421\n",
      "   macro avg       0.61      0.61      0.61      3421\n",
      "weighted avg       0.65      0.65      0.65      3421\n",
      "\n",
      "0.6541946799181526\n"
     ]
    }
   ],
   "source": [
    "DecisionTree = DecisionTreeClassifier()\n",
    "DecisionTree.fit(X_train, y_train)\n",
    "y_pred = DecisionTree.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "DT = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2094  188]\n",
      " [ 925  214]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.92      0.79      2282\n",
      "           1       0.53      0.19      0.28      1139\n",
      "\n",
      "    accuracy                           0.67      3421\n",
      "   macro avg       0.61      0.55      0.53      3421\n",
      "weighted avg       0.64      0.67      0.62      3421\n",
      "\n",
      "0.6746565331774335\n"
     ]
    }
   ],
   "source": [
    "MultinomialNB = MultinomialNB()\n",
    "MultinomialNB.fit(X_train, y_train)\n",
    "y_pred = MultinomialNB.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "MNB = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier(estimators=[('logistic',\n",
      "                              LogisticRegression(C=1.0, class_weight=None,\n",
      "                                                 dual=False, fit_intercept=True,\n",
      "                                                 intercept_scaling=1,\n",
      "                                                 l1_ratio=None, max_iter=100,\n",
      "                                                 multi_class='warn',\n",
      "                                                 n_jobs=None, penalty='l2',\n",
      "                                                 random_state=None,\n",
      "                                                 solver='warn', tol=0.0001,\n",
      "                                                 verbose=0, warm_start=False)),\n",
      "                             ('cart',\n",
      "                              RandomForestClassifier(bootstrap=True,\n",
      "                                                     class_weight=None,\n",
      "                                                     criterion...\n",
      "                                                     oob_score=False,\n",
      "                                                     random_state=None,\n",
      "                                                     verbose=0,\n",
      "                                                     warm_start=False)),\n",
      "                             ('svm',\n",
      "                              SVC(C=1.0, cache_size=200, class_weight=None,\n",
      "                                  coef0=0.0, decision_function_shape='ovr',\n",
      "                                  degree=3, gamma='auto_deprecated',\n",
      "                                  kernel='rbf', max_iter=-1, probability=False,\n",
      "                                  random_state=None, shrinking=True, tol=0.001,\n",
      "                                  verbose=False))],\n",
      "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
      "                 weights=None)\n",
      "[[2198   84]\n",
      " [ 861  278]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.96      0.82      2282\n",
      "           1       0.77      0.24      0.37      1139\n",
      "\n",
      "    accuracy                           0.72      3421\n",
      "   macro avg       0.74      0.60      0.60      3421\n",
      "weighted avg       0.73      0.72      0.67      3421\n",
      "\n",
      "0.7237649809997077\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "estimators = []\n",
    "model1 = LogisticRegression()\n",
    "estimators.append(('logistic', model1))\n",
    "model2 = RandomForestClassifier()\n",
    "estimators.append(('cart', model2))\n",
    "model3 = SVC()\n",
    "estimators.append(('svm', model3))\n",
    "\n",
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators)\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "print(ensemble)\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ensemble.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "E= accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier(estimators=[('logistic',\n",
      "                              LogisticRegression(C=1.0, class_weight=None,\n",
      "                                                 dual=False, fit_intercept=True,\n",
      "                                                 intercept_scaling=1,\n",
      "                                                 l1_ratio=None, max_iter=100,\n",
      "                                                 multi_class='warn',\n",
      "                                                 n_jobs=None, penalty='l2',\n",
      "                                                 random_state=None,\n",
      "                                                 solver='warn', tol=0.0001,\n",
      "                                                 verbose=0, warm_start=False)),\n",
      "                             ('cart',\n",
      "                              RandomForestClassifier(bootstrap=True,\n",
      "                                                     class_weight=None,\n",
      "                                                     criterion...\n",
      "                                            class_weight=None,\n",
      "                                            early_stopping=False, epsilon=0.1,\n",
      "                                            eta0=0.0, fit_intercept=True,\n",
      "                                            l1_ratio=0.15,\n",
      "                                            learning_rate='optimal',\n",
      "                                            loss='hinge', max_iter=5,\n",
      "                                            n_iter_no_change=5, n_jobs=None,\n",
      "                                            penalty='l2', power_t=0.5,\n",
      "                                            random_state=None, shuffle=True,\n",
      "                                            tol=0.001, validation_fraction=0.1,\n",
      "                                            verbose=0, warm_start=False))],\n",
      "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
      "                 weights=None)\n",
      "[[2229   53]\n",
      " [ 875  264]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.98      0.83      2282\n",
      "           1       0.83      0.23      0.36      1139\n",
      "\n",
      "    accuracy                           0.73      3421\n",
      "   macro avg       0.78      0.60      0.60      3421\n",
      "weighted avg       0.76      0.73      0.67      3421\n",
      "\n",
      "0.7287342882198188\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "estimators = []\n",
    "model1 = LogisticRegression()\n",
    "estimators.append(('logistic', model1))\n",
    "model2 = RandomForestClassifier()\n",
    "estimators.append(('cart', model2))\n",
    "model3 = SVC()\n",
    "estimators.append(('svm', model3))\n",
    "model4 = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5)\n",
    "estimators.append(('sgd', model4))\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "# create the ensemble model\n",
    "ensemble2 = VotingClassifier(estimators)\n",
    "\n",
    "print(ensemble2)\n",
    "\n",
    "ensemble2.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ensemble2.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "E2 = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier(estimators=[('logistic',\n",
      "                              LogisticRegression(C=1.0, class_weight=None,\n",
      "                                                 dual=False, fit_intercept=True,\n",
      "                                                 intercept_scaling=1,\n",
      "                                                 l1_ratio=None, max_iter=100,\n",
      "                                                 multi_class='warn',\n",
      "                                                 n_jobs=None, penalty='l2',\n",
      "                                                 random_state=None,\n",
      "                                                 solver='warn', tol=0.0001,\n",
      "                                                 verbose=0, warm_start=False)),\n",
      "                             ('cart',\n",
      "                              RandomForestClassifier(bootstrap=True,\n",
      "                                                     class_weight=None,\n",
      "                                                     criterion...\n",
      "                                            class_weight=None,\n",
      "                                            early_stopping=False, epsilon=0.1,\n",
      "                                            eta0=0.0, fit_intercept=True,\n",
      "                                            l1_ratio=0.15,\n",
      "                                            learning_rate='optimal',\n",
      "                                            loss='hinge', max_iter=5,\n",
      "                                            n_iter_no_change=5, n_jobs=None,\n",
      "                                            penalty='l2', power_t=0.5,\n",
      "                                            random_state=None, shuffle=True,\n",
      "                                            tol=0.001, validation_fraction=0.1,\n",
      "                                            verbose=0, warm_start=False))],\n",
      "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
      "                 weights=None)\n",
      "[[2013  269]\n",
      " [ 708  431]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.88      0.80      2282\n",
      "           1       0.62      0.38      0.47      1139\n",
      "\n",
      "    accuracy                           0.71      3421\n",
      "   macro avg       0.68      0.63      0.64      3421\n",
      "weighted avg       0.70      0.71      0.69      3421\n",
      "\n",
      "0.7144109909383222\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "estimators = []\n",
    "model1 = LogisticRegression()\n",
    "estimators.append(('logistic', model1))\n",
    "model2 = RandomForestClassifier()\n",
    "estimators.append(('cart', model2))\n",
    "model4 = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5)\n",
    "estimators.append(('sgd', model4))\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "# create the ensemble model\n",
    "ensemble3 = VotingClassifier(estimators)\n",
    "\n",
    "print(ensemble3)\n",
    "\n",
    "ensemble3.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ensemble3.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "E3 = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier(estimators=[('logistic',\n",
      "                              LogisticRegression(C=1.0, class_weight=None,\n",
      "                                                 dual=False, fit_intercept=True,\n",
      "                                                 intercept_scaling=1,\n",
      "                                                 l1_ratio=None, max_iter=100,\n",
      "                                                 multi_class='warn',\n",
      "                                                 n_jobs=None, penalty='l2',\n",
      "                                                 random_state=None,\n",
      "                                                 solver='warn', tol=0.0001,\n",
      "                                                 verbose=0, warm_start=False)),\n",
      "                             ('cart',\n",
      "                              DecisionTreeClassifier(class_weight=None,\n",
      "                                                     criterion='gini',\n",
      "                                                     max_dep...\n",
      "                                                     min_weight_fraction_leaf=0.0,\n",
      "                                                     presort=False,\n",
      "                                                     random_state=None,\n",
      "                                                     splitter='best')),\n",
      "                             ('svm',\n",
      "                              SVC(C=1.0, cache_size=200, class_weight=None,\n",
      "                                  coef0=0.0, decision_function_shape='ovr',\n",
      "                                  degree=3, gamma='auto_deprecated',\n",
      "                                  kernel='rbf', max_iter=-1, probability=False,\n",
      "                                  random_state=None, shrinking=True, tol=0.001,\n",
      "                                  verbose=False))],\n",
      "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
      "                 weights=None)\n",
      "[[2153  129]\n",
      " [ 817  322]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.94      0.82      2282\n",
      "           1       0.71      0.28      0.41      1139\n",
      "\n",
      "    accuracy                           0.72      3421\n",
      "   macro avg       0.72      0.61      0.61      3421\n",
      "weighted avg       0.72      0.72      0.68      3421\n",
      "\n",
      "0.7234726688102894\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "# create the sub models\n",
    "estimators = []\n",
    "model1 = LogisticRegression()\n",
    "estimators.append(('logistic', model1))\n",
    "model2 = DecisionTreeClassifier()\n",
    "estimators.append(('cart', model2))\n",
    "model3 = SVC()\n",
    "estimators.append(('svm', model3))\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# create the ensemble model\n",
    "ensemble4 = VotingClassifier(estimators)\n",
    "\n",
    "print(ensemble4)\n",
    "\n",
    "ensemble4.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ensemble4.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "E4 = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier(estimators=[('logistic',\n",
      "                              LogisticRegression(C=1.0, class_weight=None,\n",
      "                                                 dual=False, fit_intercept=True,\n",
      "                                                 intercept_scaling=1,\n",
      "                                                 l1_ratio=None, max_iter=100,\n",
      "                                                 multi_class='warn',\n",
      "                                                 n_jobs=None, penalty='l2',\n",
      "                                                 random_state=None,\n",
      "                                                 solver='warn', tol=0.0001,\n",
      "                                                 verbose=0, warm_start=False)),\n",
      "                             ('cart',\n",
      "                              DecisionTreeClassifier(class_weight=None,\n",
      "                                                     criterion='gini',\n",
      "                                                     max_dep...\n",
      "                                                     oob_score=False,\n",
      "                                                     random_state=None,\n",
      "                                                     verbose=0,\n",
      "                                                     warm_start=False)),\n",
      "                             ('svm',\n",
      "                              SVC(C=1.0, cache_size=200, class_weight=None,\n",
      "                                  coef0=0.0, decision_function_shape='ovr',\n",
      "                                  degree=3, gamma='auto_deprecated',\n",
      "                                  kernel='rbf', max_iter=-1, probability=False,\n",
      "                                  random_state=None, shrinking=True, tol=0.001,\n",
      "                                  verbose=False))],\n",
      "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
      "                 weights=None)\n",
      "[[2230   52]\n",
      " [ 890  249]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.98      0.83      2282\n",
      "           1       0.83      0.22      0.35      1139\n",
      "\n",
      "    accuracy                           0.72      3421\n",
      "   macro avg       0.77      0.60      0.59      3421\n",
      "weighted avg       0.75      0.72      0.67      3421\n",
      "\n",
      "0.7246419175679626\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "estimators = []\n",
    "model1 = LogisticRegression()\n",
    "estimators.append(('logistic', model1))\n",
    "model2 = DecisionTreeClassifier()\n",
    "estimators.append(('cart', model2))\n",
    "model3 = RandomForestClassifier()\n",
    "estimators.append(('rf', model3))\n",
    "model4 = SVC()\n",
    "estimators.append(('svm', model4))\n",
    "#model4 = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5)\n",
    "#estimators.append(('sgd', model4))\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "# create the ensemble model\n",
    "ensemble5 = VotingClassifier(estimators)\n",
    "\n",
    "print(ensemble5)\n",
    "\n",
    "ensemble5.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ensemble5.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "E5 = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier(estimators=[('logistic',\n",
      "                              LogisticRegression(C=1.0, class_weight=None,\n",
      "                                                 dual=False, fit_intercept=True,\n",
      "                                                 intercept_scaling=1,\n",
      "                                                 l1_ratio=None, max_iter=100,\n",
      "                                                 multi_class='warn',\n",
      "                                                 n_jobs=None, penalty='l2',\n",
      "                                                 random_state=None,\n",
      "                                                 solver='warn', tol=0.0001,\n",
      "                                                 verbose=0, warm_start=False)),\n",
      "                             ('cart',\n",
      "                              DecisionTreeClassifier(class_weight=None,\n",
      "                                                     criterion='gini',\n",
      "                                                     max_dep...\n",
      "                                            class_weight=None,\n",
      "                                            early_stopping=False, epsilon=0.1,\n",
      "                                            eta0=0.0, fit_intercept=True,\n",
      "                                            l1_ratio=0.15,\n",
      "                                            learning_rate='optimal',\n",
      "                                            loss='hinge', max_iter=5,\n",
      "                                            n_iter_no_change=5, n_jobs=None,\n",
      "                                            penalty='l2', power_t=0.5,\n",
      "                                            random_state=None, shuffle=True,\n",
      "                                            tol=0.001, validation_fraction=0.1,\n",
      "                                            verbose=0, warm_start=False))],\n",
      "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
      "                 weights=None)\n",
      "[[2118  164]\n",
      " [ 774  365]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.93      0.82      2282\n",
      "           1       0.69      0.32      0.44      1139\n",
      "\n",
      "    accuracy                           0.73      3421\n",
      "   macro avg       0.71      0.62      0.63      3421\n",
      "weighted avg       0.72      0.73      0.69      3421\n",
      "\n",
      "0.7258111663256358\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "estimators = []\n",
    "model1 = LogisticRegression()\n",
    "estimators.append(('logistic', model1))\n",
    "model2 = DecisionTreeClassifier()\n",
    "estimators.append(('cart', model2))\n",
    "model3 = RandomForestClassifier()\n",
    "estimators.append(('rf', model3))\n",
    "model4 = SVC()\n",
    "estimators.append(('svm', model4))\n",
    "model5 = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5)\n",
    "estimators.append(('sgd', model5))\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "# create the ensemble model\n",
    "ensemble6 = VotingClassifier(estimators)\n",
    "\n",
    "print(ensemble6)\n",
    "\n",
    "ensemble6.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ensemble6.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "E6 = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier(estimators=[('logistic',\n",
      "                              LogisticRegression(C=1.0, class_weight=None,\n",
      "                                                 dual=False, fit_intercept=True,\n",
      "                                                 intercept_scaling=1,\n",
      "                                                 l1_ratio=None, max_iter=100,\n",
      "                                                 multi_class='warn',\n",
      "                                                 n_jobs=None, penalty='l2',\n",
      "                                                 random_state=None,\n",
      "                                                 solver='warn', tol=0.0001,\n",
      "                                                 verbose=0, warm_start=False)),\n",
      "                             ('cart',\n",
      "                              DecisionTreeClassifier(class_weight=None,\n",
      "                                                     criterion='gini',\n",
      "                                                     max_dep...\n",
      "                                            loss='hinge', max_iter=5,\n",
      "                                            n_iter_no_change=5, n_jobs=None,\n",
      "                                            penalty='l2', power_t=0.5,\n",
      "                                            random_state=None, shuffle=True,\n",
      "                                            tol=0.001, validation_fraction=0.1,\n",
      "                                            verbose=0, warm_start=False)),\n",
      "                             ('ada',\n",
      "                              AdaBoostClassifier(algorithm='SAMME.R',\n",
      "                                                 base_estimator=None,\n",
      "                                                 learning_rate=1.0,\n",
      "                                                 n_estimators=100,\n",
      "                                                 random_state=0))],\n",
      "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
      "                 weights=None)\n",
      "[[2201   81]\n",
      " [ 842  297]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.96      0.83      2282\n",
      "           1       0.79      0.26      0.39      1139\n",
      "\n",
      "    accuracy                           0.73      3421\n",
      "   macro avg       0.75      0.61      0.61      3421\n",
      "weighted avg       0.74      0.73      0.68      3421\n",
      "\n",
      "0.7301958491669103\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "estimators = []\n",
    "model1 = LogisticRegression()\n",
    "estimators.append(('logistic', model1))\n",
    "model2 = DecisionTreeClassifier()\n",
    "estimators.append(('cart', model2))\n",
    "model3 = RandomForestClassifier()\n",
    "estimators.append(('rf', model3))\n",
    "model4 = SVC()\n",
    "estimators.append(('svm', model4))\n",
    "model5 = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5)\n",
    "estimators.append(('sgd', model5))\n",
    "model6 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "estimators.append(('ada', model6))\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "# create the ensemble model\n",
    "ensemble7 = VotingClassifier(estimators)\n",
    "\n",
    "print(ensemble7)\n",
    "\n",
    "ensemble7.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ensemble7.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "E7 = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier(estimators=[('logistic',\n",
      "                              LogisticRegression(C=1.0, class_weight=None,\n",
      "                                                 dual=False, fit_intercept=True,\n",
      "                                                 intercept_scaling=1,\n",
      "                                                 l1_ratio=None, max_iter=100,\n",
      "                                                 multi_class='warn',\n",
      "                                                 n_jobs=None, penalty='l2',\n",
      "                                                 random_state=None,\n",
      "                                                 solver='warn', tol=0.0001,\n",
      "                                                 verbose=0, warm_start=False)),\n",
      "                             ('cart',\n",
      "                              DecisionTreeClassifier(class_weight=None,\n",
      "                                                     criterion='gini',\n",
      "                                                     max_dep...\n",
      "                                            verbose=0, warm_start=False)),\n",
      "                             ('ada',\n",
      "                              AdaBoostClassifier(algorithm='SAMME.R',\n",
      "                                                 base_estimator=None,\n",
      "                                                 learning_rate=1.0,\n",
      "                                                 n_estimators=100,\n",
      "                                                 random_state=0)),\n",
      "                             ('knn',\n",
      "                              KNeighborsClassifier(algorithm='auto',\n",
      "                                                   leaf_size=30,\n",
      "                                                   metric='minkowski',\n",
      "                                                   metric_params=None,\n",
      "                                                   n_jobs=None, n_neighbors=3,\n",
      "                                                   p=2, weights='uniform'))],\n",
      "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
      "                 weights=None)\n",
      "[[2095  187]\n",
      " [ 765  374]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.92      0.81      2282\n",
      "           1       0.67      0.33      0.44      1139\n",
      "\n",
      "    accuracy                           0.72      3421\n",
      "   macro avg       0.70      0.62      0.63      3421\n",
      "weighted avg       0.71      0.72      0.69      3421\n",
      "\n",
      "0.7217187956737796\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "estimators = []\n",
    "model1 = LogisticRegression()\n",
    "estimators.append(('logistic', model1))\n",
    "model2 = DecisionTreeClassifier()\n",
    "estimators.append(('cart', model2))\n",
    "model3 = RandomForestClassifier()\n",
    "estimators.append(('rf', model3))\n",
    "model4 = SVC()\n",
    "estimators.append(('svm', model4))\n",
    "model5 = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5)\n",
    "estimators.append(('sgd', model5))\n",
    "model6 = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "estimators.append(('ada', model6))\n",
    "model7 = KNeighborsClassifier(n_neighbors=3)\n",
    "estimators.append(('knn', model7))\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "# create the ensemble model\n",
    "ensemble8 = VotingClassifier(estimators)\n",
    "\n",
    "print(ensemble8)\n",
    "\n",
    "ensemble8.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ensemble8.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "E8 = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = [LR, RF, AB, SGDA, KNNA, DT, MNB, E, E2, E3, E4, E5, E6, E7, E8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(accuracies)):\n",
    "    accuracies[i] = accuracies[i]*100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[70.53493130663549,\n",
       " 70.53493130663549,\n",
       " 70.24261911721719,\n",
       " 67.0271850336159,\n",
       " 55.451622332651276,\n",
       " 65.41946799181527,\n",
       " 67.46565331774335,\n",
       " 72.37649809997076,\n",
       " 72.87342882198188,\n",
       " 71.44109909383222,\n",
       " 72.34726688102894,\n",
       " 72.46419175679625,\n",
       " 72.58111663256358,\n",
       " 73.01958491669103,\n",
       " 72.17187956737796]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['LogitR' , 'RF', 'AdaB', 'SGDA', 'KNN', 'DT', 'MNB', 'E', 'E2','E3', 'E4', 'E5', 'E6', 'E7', 'E8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(models,accuracies)\n",
    "plt.xlabel(\"Algortithm\")\n",
    "plt.ylabel(\"Accuracy (in %)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
